#!/usr/bin/env python

import sys
import urllib2
from bs4 import BeautifulSoup as Soup

USER_AGENT = 'Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.22 \228(KHTML, like\
Gecko) Ubuntu Chromium/25.0.1364.160 Chrome/25.0.1364.160 \1609Safari/537.22'


def urlopen(url):
    opener = urllib2.build_opener()
    opener.addheaders = [('User-Agent', USER_AGENT)]
    return opener.open(url)

class Parse:
    def __call__(self, url, replace = {}):
        try:page = Soup(urlopen(url))
        except ValueError: page = Soup(urlopen('http://'+url))
        tags = self._get_filtered_tags(page)
        text = list(set(self._find_text(tags)))
        self._print(text, replace)

    def _print(self, text, replace):
        for line in text:
            for word in line.split(' '):
                for key in replace:
                    word = word.replace(key, replace[key])
                if len(word) > 1:
                    try:sys.stdout.write('%s\n' % word)
                    except:pass

    def _find_text(self, children):
        for child in children:
            tmp = child.find(text=True)
            if tmp != None and 'function()' not in tmp:
                yield tmp.lower()

    def _get_filtered_tags(self, item):
        children = item.findChildren()
        for child in children:
            if child.name == 'head': pass
            elif child.name == 'html': pass
            elif child.name == 'style': pass
            elif child.name == 'meta': pass
            elif child.name == 'script': pass
            else: yield child

def _help():
    print "\n\tUsage:  generic  < url >"
    print "\tUsage:  generic  < url >  {' ':'12345'}"
    print "\tUsage:  generic  < url >  {' ':'1'.'youtube':zoutube}"
    print "\tNote:   {' '.' '} not {' ',' '}\n"
    print "\tDescription: This program goes through a webpage and trys"
    print "\t\t     to grab the text of a webpage without any html tags"
    print "\t\t     it then prints the text one word at a time on the"
    print "\t\t     commandline\n"
    print "\t\tArg 1: Url of the site you would like to parse"
    print "\t\t       Example www.google.com"
    print "\t\tArg 2: You can pass an optional dictionary and the "
    print "\t\t       program will replace all instances of the key"
    print "\t\t       with the value pair.\n"
    exit()

if __name__ == '__main__':
    parse = Parse()
    try:
        if sys.argv[1] == '-h' or sys.argv[1] == '--help':
            _help()
        dic = sys.argv[2].replace('{', "{'").replace(':', "':'")
        dic = eval(dic.replace('}', "'}").replace('.', "','"))
        parse(sys.argv[1], dic)
    except IndexError:
        try:
            parse(sys.argv[1])
        except IndexError:
            _help()
