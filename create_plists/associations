#!/usr/bin/env python
import sys
import urllib2
from bs4 import BeautifulSoup as Soup


USER_AGENT = 'Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.22 \228(KHTML, like\
Gecko) Ubuntu Chromium/25.0.1364.160 Chrome/25.0.1364.160 \1609Safari/537.22'

def urlopen(url):
    opener = urllib2.build_opener()
    opener.addheaders = [('User-Agent', USER_AGENT)]
    return opener.open(url)

class Parse:
    def __init__(self):
        self.valid = []

    def __call__(self, dictionary, search_depth):
        results = list(open(dictionary, 'r'))
        for x in xrange(int(search_depth)):
            sys.stderr.write('round %s of %s\n' % (x + 1, search_depth))
            results = list(self._find_results(results))

    def _find_results(self, word_list):
        for word in word_list:
            page = Soup(urlopen('http://wordassociations.net/search?hl=en&w=%s' % word))
            for link in page('a'):
                if link.has_attr('href') and '/search?hl=en&w=' in link['href']:
                    found = link['href'][16:].lower()
                    if '&' not in found and found not in self.valid:
                        yield found
                        self.valid.append(found)
                        try:sys.stdout.write('%s\n' % found)
                        except:pass


if __name__ == '__main__':
    try:
        parse = Parse()
        parse(sys.argv[1], sys.argv[2])
    except IndexError:
        print "\n\tUsage:  associations.py  < dictionary >  < search depth >"
        print "\n\tDescription: This program uses wordassociations.net to gather"
        print "\t\t     a new list of words associated with the words from the"
        print "\t\t     dictionary provided\n"
        print "\t\tArg 1: Dictionary oo words\n"
