#!/usr/bin/env python

import sys
import urllib2
from bs4 import BeautifulSoup as Soup

USER_AGENT = 'Mozilla/5.0'\


def urlopen(url):
    opener = urllib2.build_opener()
    opener.addheaders = [('User-Agent', USER_AGENT)]
    return opener.open(url)

class Parse:
    def __init__(self, max_length = 64):
        self.valid = []
        self._max_length = max_length

    def __call__(self, argv):
        urls = self._create_urls(argv)
        for url in urls:
            sys.stderr.write(url + '\n')
            try:
                try:page = Soup(urlopen(url))
                except ValueError: page = Soup(urlopen('http://'+url))
                tags = self._get_filtered_tags(page)
                text = list(set(self._find_text(tags)))
                self._create_words(text)
                self._print()
            except:
                pass

    def _create_urls(self, argv):
        google_encode = '+'.join(argv)
        url = 'https://www.google.com/search?q=' + google_encode
        page = Soup(urlopen(url))
        urls = []
        for link in page('a'):
            if link.has_attr('href'):
                if link['href'].startswith('/url?q='):
                    if not 'www.youtube.com' in link['href'] and \
                       not 'webcache.googleusercontent.com' in link['href'] and\
                       not 'www.facebook.com' in link['href']:
                        url = str(link['href'][7:])
                        urls.append(url.split('&')[0])
        return urls


    def _print(self):
        for word in sorted(list(set(self.valid))):
            try:
                print word
            except:
                pass

    def _create_words(self, text):
        for line in text:
            if ' ' in line:
                words = line.split(' ')
                for word in words:
                    compound = ''
                    for compounds in words[words.index(word):]:
                        compound += compounds + ' '
                        if len(compound) < self._max_length:
                            self.valid.append(compound)
            else:
                self.valid.append(line[:self._max_length])

    def _find_text(self, children):
        valid = []
        for child in children:
            tmp = child.find(text=True)
            if tmp != None and 'function()' not in tmp:
                if tmp not in valid: valid.append(tmp.lower())
        return valid

    def _get_filtered_tags(self, item):
        valid = []
        children = item.findChildren()
        for child in children:
            if child.name == 'head': pass
            elif child.name == 'html': pass
            elif child.name == 'style': pass
            elif child.name == 'meta': pass
            elif child.name == 'script': pass
            else: valid.append(child)
        return valid

def _help():
    print "\n\tUsage:  google.py  < search string ... >"
    print "\n\tDescription: This program takes a search string and gets googles"
    print "\t\t     results. It then navigates to those results and trys"
    print "\t\t     to grab the text of each webpage without any html tags"
    print "\t\t     it then prints the text one word at a time on the"
    print "\t\t     commandline\n"
    print "\t\tArgs: takes a google search string"
    print "\t\t       Example Tonka"

if __name__ == '__main__':
    try:
        if sys.argv[1] == '-h' or sys.argv[1] == '--help':
            _help()
            exit()
        parse = Parse()
        parse(sys.argv[1:])
    except IndexError:
        _help()


